---
layout: post
title: K8S环境搭建
date: 2023-07-28
tags: k8s   
---

## 基础环境配置

### 主机名规划

|IP|域名|主机名|
|---------|--------------------------  |-----------------|
|10.0.0.12| kubernetes-master.xy.com   |kubernetes-master|
|10.0.0.15| kubernetes-node1.xy.com    |kubernetes-node1|
|10.0.0.16| kubernetes-node2.xy.com    |kubernetes-node2|
|10.0.0.17| kubernetes-node3.xy.com    |kubernetes-node3|
|10.0.0.20| kubernetes-register.xy.com |kubernetes-register|

### 禁用swap分区

- 临时禁用
  
  `swapoff -a`

- 永久禁用
  
  `sed -i 's/.*swap.*/#&/' /etc/fstab`

### 内核参数调整

  ```shell
  cat >> /etc/sysctl.d/k8s.conf << EOF
  vm.swappiness=0
  EOF
  ```

`sysctl -p /etc/sysctl.d/k8s.conf`

### 网络参数调整

- 配置iptables参数，使得流经过网桥的流量也经过iptables/netfilter防火墙

  ```shell
  cat >> /etc/sysctl.d/k8s.conf << EOF
  net.bridge.bridge-nf-call-iptables  = 1
  net.bridge.bridge-nf-call-ip6tables = 1
  net.ipv4.ip_forward                 = 1
  EOF
  ```

- 配置生效
  
  ```shell
  modprobe overlay
  modprobe br_netfilter
  sysctl -p /etc/sysctl.d/k8s.conf
  ```

## 容器环境操作

> 注意： 所有主机操作

### 配置docker软件源

  ```shell
  yum install -y yum-utils device-mapper-persistent-data lvm2

  yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
  ```

### 安装最新版docker

  ```shell
  yum list docker-ce.x86_64 --showduplicates | sort -r
  yum -y install docker-ce
  systemctl enable docker
  systemctl start docker
  ```

### docker加速器配置（镜像主机无需配置）

  ```shell
    cat >> /etc/docker/daemon.json << EOF
    {
      "registry-mirrors": [
        "https://125r384o.mirror.aliyuncs.com",
        "https://registry.docker-cn.com",
        "https://hub-mirror.c.163.com",
        "https://docker.mirrors.ustc.edu.cn"
        ],
        "insecure-registries": ["kubernetes-register.xy.com"],
        "exec-opts": ["native.cgroupdriver=systemd"]
    }
    EOF
  ```

  `systemctl restart docker`

### cri环境配置

> 注意： 除了harbor机器，其他所有主机操作

- cri-docker.service

```shell
cat > /etc/systemd/system/cri-docker.service << EOF
[Unit]
Description=CRI Interface for Docker Application Container Engine
Documentation=https://docs.mirantis.com
After=network-online.target firewalld.service docker.service
Wants=network-online.target
Requires=cri-docker.socket

[Service]
Type=notify
ExecStart=/usr/local/bin/cri-dockerd --pod-infra-container-image=kubernetes-register.xy.com/google_containers/pause:3.9 --network-plugin=cni --cni-conf-dir=/etc/cni.d  --cni-bin-dir=/opt/cni/bin --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --cri-dockerd-root-directory=/var/lib/docker --docker-endpoint=unix:///var/run/docker.sock
ExecReload=/bin/kill -s HUP $MAINPID
TimeoutSec=0
RestartSec=2
Restart=always

# Note that StartLimit* options were moved from "Service" to "Unit" in systemd 229.
# Both the old, and new location are accepted by systemd 229 and up, so using the old location
# to make them work for either version of systemd.
StartLimitBurst=3

# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
# this option work for either version of systemd.
StartLimitInterval=60s

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Comment TasksMax if your systemd version does not support it.
# Only systemd 226 and above support this option.
TasksMax=infinity
Delegate=yes
KillMode=process

[Install]
WantedBy=multi-user.target
EOF
```

- cri-docker.socket

```shell
cat > /etc/systemd/system/cri-docker.socket << EOF
[Unit]
Description=CRI Docker Socket for the API
PartOf=cri-docker.service

[Socket]
ListenStream=/var/run/cri-dockerd.sock
SocketMode=0660
SocketUser=root
SocketGroup=docker

[Install]
WantedBy=sockets.target
EOF
```

```shell
mkdir -p /data/soft
cd /data/soft
VERSION="0.3.4"
ARCH="amd64"
wget https://github.com/Mirantis/cri-dockerd/releases/download/v${VERSION}/cri-dockerd-${VERSION}.${ARCH}.tgz
tar xvf cri-dockerd-${VERSION}.${ARCH}.tgz
cd cri-dockerd
cp cri-dockerd /usr/local/bin
systemctl daemon-reload
systemctl enable cri-docker.service
systemctl start cri-docker.service
```

## harbor安装

### 准备工作

```shell
yum install epel-relase
yum update 
yum install docker-compose
```

### 获取软件

```shell
mkdir /data/{softs,server} -p && cd /data/softs
wget https://github.com/goharbor/harbor/releases/download/v2.9.2/harbor-offline-installer-v2.9.2.tgz

tar -zxvf harbor-offline-installer-v2.9.2.tgz -C /data/server/
cd /data/server/harbor/
docker load < harbor.v2.9.2.tar.gz 
docker images
```

### 配置

### 修改配置文件

```shell
cp harbor.yml.tmpl harbor.yml
sed -ri.bak 's/(^hostname:)\s+[a-z.]+/\1 kubernetes-register.xy.com/' harbor.yml
sed -ri.bak 's/(^https:)/#\1/' harbor.yml
sed -ri.bak 's/(certificate:)/#\1/' harbor.yml
sed -ri.bak 's/(private_key:)/#\1/' harbor.yml
sed -ri.bak 's|(data_volume:\s+)[/a-z]|\1/data/server/harbor/|' harbor.yml
```

### 命令行启动

```shell
./prepare
./install.sh
```

检查效果

```shell
docker-compose ps
```

### systemd管理

- harbor.service

```shell
cat > /etc/systemd/system/harbor.service << EOF
# https://github.com/goharbor/harbor/blob/main/tools/systemd/harbor.service
[Unit]
Description=Harbor Cloud Native Registry
Documentation=https://goharbor.io
After=docker.service
Requires=docker.service

[Service]
Type=simple
Restart=on-failure
RestartSec=5
ExecStart=/usr/bin/docker-compose -f /data/server/harbor/docker-compose.yml up
ExecStop=/usr/bin/docker-compose -f /data/server/harbor/docker-compose.yml down -v
ExecStopPost=/usr/bin/docker-compose -f /data/server/harbor/docker-compose.yml rm -f

[Install]
WantedBy=multi-user.target
EOF
```

- 启动服务

```shell
systemctl daemon-reload
systemctl start harbor
systemctl enable harbor
systemctl status harbor
```

### harbor设置

- 创建用户

- 新建项目

1. 使用新建的用户来创建

2. 访问级别设置为“公开”

- harbor仓库测试

```shell
docker login kubernetes-register.xy.com -u xy
docker pull busybox
docker tag busybox kubernetes-register.xy.com/xy/busybox:v0.1
docker push kubernetes-register.xy.com/xy/busybox:v0.1
```

## k8s环境初始化

- 配置镜像源
镜像站：https://developer.aliyun.com/mirror/?spm=a2c6h.12883283.J_eBhO-wcawiLJRkGqHmozR.68.486a4307K5zTht

```shell
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

# 更新软件源
yum makecache fast
```

- master安装kubelet kubeadm kubectl

```shell
yum install -y kubelet kubeadm kubectl
systemctl enable kubelet && systemctl start kubelet
```

- node安装kubelet kubeadm kubectl

```shell
yum install -y kubelet kubeadm kubectl
systemctl enable kubelet && systemctl start kubelet
```

- 确认基本配置

```shell
# 检查镜像文件列表
kubeadm config image list

# 获取镜像文件
# images=$(kubeadm config images list  --kubernetes-version=1.28.2|awk -F '/' '{print $NF}')
images=$(kubeadm config images list  --kubernetes-version=1.27.3|awk -F '/' '{print $NF}')
for i in $images
do
  docker pull registry.aliyuncs.com/google_containers/$i
  docker tag registry.aliyuncs.com/google_containers/$i kubernetes-register.xy.com/google_containers/$i
  docker push kubernetes-register.xy.com/google_containers/$i
  docker rmi registry.aliyuncs.com/google_containers/$i
done
```

- master环境初始化

```shell
kubeadm init --kubernetes-version=1.27.3 --apiserver-advertise-address=10.0.0.12 --image-repository=kubernetes-register.xy.com/google_containers --pod-network-cidr="10.224.0.0/16" --service-cidr="10.96.0.0/12" --ignore-preflight-errors=Swap  --cri-socket=unix:///var/run/cri-dockerd.sock
```

- node节点加入

```shell
kubeadm join 10.0.0.12:6443 --token p8u21f.ddq7zc6s3oe1affs \
   --discovery-token-ca-cert-hash sha256:d4a845213e172044d8fba1e6d51618c89c7f5514b5d837e1aefb11adc38b6e71 \
        --cri-socket=unix:///var/run/cri-dockerd.sock
```

## 其他设置

- 认证

```shell
mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config
```

- 命令补全

```shell
yum install bash-completion
source /usr/share/bash-completion/bash_completion

echo "source <(kubectl completion bash)" >> ~/.bashrc
echo "source <(kubeadm completion bash)" >> ~/.bashrc
source ~/.bashrc
```

- 安装网络插件

```shell
# https://kubernetes.io/docs/concepts/cluster-administration/addons/
# https://github.com/flannel-io/flannel#deploying-flannel-manually
mkdir -p /data/kubenetes/network/flannel
cd /data/kubenetes/network/flannel
wget https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
cp kube-flannel.yml{,.bak}

grep image kube-flannel.yml

docker pull flannel/flannel:v0.24.4
docker pull flannel/flannel-cni-plugin:v1.4.0-flannel1

docker tag flannel/flannel:v0.24.4  kubernetes-register.xy.com/xy/flannel:v0.24.4
docker tag flannel/flannel-cni-plugin:v1.4.0-flannel1 kubernetes-register.xy.com/xy/flannel-cni-plugin:v1.4.0-flannel1

docker push kubernetes-register.xy.com/xy/flannel:v0.24.4
docker push kubernetes-register.xy.com/xy/flannel-cni-plugin:v1.4.0-flannel1

# 修改kube-flannel.yml镜像配置
```